{
 "cells": [
  {
   "cell_type": "raw",
   "id": "49e92b03",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Change point detection in Python\"\n",
    "subtitle: \"Fundamentals of reproducible research and free software (MVA 2022-2023)\"\n",
    "author: \"Charles Truong\"\n",
    "date: 2022-11-23\n",
    "format:\n",
    "    revealjs:\n",
    "        code-fold: true\n",
    "        footer: \"C. Truong - Fundamentals of reproducible research and free software (MVA 2022-2023)\"\n",
    "        output: true\n",
    "        fig-width: 10\n",
    "jupyter: python3\n",
    "execute:\n",
    "    keep-ipynb: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707831d2",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Setup {.smaller}\n",
    "\n",
    "- Download the code at [github.com/deepcharles/music-segmentation](https://github.com/deepcharles/music-segmentation).\n",
    "\n",
    "![QR code](qr-code.png)\n",
    "\n",
    "- Install the librairies in the `requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78958d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import ruptures as rpt  # our package\n",
    "from IPython.display import Audio, display\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "SAMPLING_RATE = 22050  # Hz\n",
    "HOP_LENGTH_TEMPO = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102e8b99",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def fig_ax(figsize=(15, 5), dpi=150):\n",
    "    \"\"\"Return a (matplotlib) figure and ax objects with given size.\"\"\"\n",
    "    return plt.subplots(figsize=figsize, dpi=dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91822424",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load the data {.smaller .scrollable}\n",
    "\n",
    "- A number of music files are available in Librosa.\n",
    "- Here, we choose the Dance of the _Sugar Plum Fairy_ from _The Nutcracker_ by Tchaikovsky.\n",
    "\n",
    "Listen to the music as well as display the sound envelope.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "\n",
    "duration = 30  # in seconds\n",
    "signal, _ = librosa.load(librosa.ex(\"nutcracker\"), duration=duration)\n",
    "\n",
    "# listen to the music\n",
    "display(Audio(data=signal, rate=SAMPLING_RATE))\n",
    "\n",
    "# look at the envelope\n",
    "fig, ax = fig_ax()\n",
    "ax.plot(np.arange(signal.size) / SAMPLING_RATE, signal)\n",
    "ax.set_xlim(0, signal.size / SAMPLING_RATE)\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "_ = ax.set(title=\"Sound envelope\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118152e2-06ef-4665-9037-c2ca663816a9",
   "metadata": {},
   "source": [
    "## Signal transformation\n",
    "\n",
    "- Transform the signal into a tempogram\n",
    "\n",
    "- The tempogram measures the tempo (measured in Beats Per Minute, BPM) profile along the time axis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b19c68-071f-41f4-afaf-9cf4251e6a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "\n",
    "def get_tempogram(signal: np.ndarray,\n",
    "                  hop_length_tempo: int=HOP_LENGTH_TEMPO)->np.ndarray:\n",
    "    \"\"\"Return the tempogram of a sound signal.\"\"\"\n",
    "    # Compute the onset strength\n",
    "    oenv = librosa.onset.onset_strength(\n",
    "        y=signal, sr=SAMPLING_RATE, hop_length=hop_length_tempo\n",
    "    )\n",
    "    # Compute the tempogram\n",
    "    tempogram = librosa.feature.tempogram(\n",
    "        onset_envelope=oenv,\n",
    "        sr=SAMPLING_RATE,\n",
    "        hop_length=hop_length_tempo,\n",
    "    )\n",
    "    return tempogram.T\n",
    "\n",
    "tempogram = get_tempogram(signal=signal, hop_length_tempo=256)\n",
    "\n",
    "# Display the tempogram\n",
    "fig, ax = fig_ax()\n",
    "_ = librosa.display.specshow(\n",
    "    tempogram.T,\n",
    "    ax=ax,\n",
    "    hop_length=HOP_LENGTH_TEMPO,\n",
    "    sr=SAMPLING_RATE,\n",
    "    x_axis=\"s\",\n",
    "    y_axis=\"tempo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11df2a8f-288f-4b61-8255-6e1b58b5c543",
   "metadata": {},
   "source": [
    "## Detection algorithm\n",
    "\n",
    "- Search method: dynamic programming (exact).\n",
    "- We choose to detect changes in the mean of the tempogram, which is a multivariate signal. Associated cost function: $$c(y_{a..b}) = \\sum_{t=a}^{b-1} \\|y_t - \\bar{y}_{a..b} \\|^2$$\n",
    "- What about the number of change-points?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6585df1-683b-4c41-8d65-bfcb0de9a740",
   "metadata": {},
   "source": [
    "## Number of change-points {.smaller .scrollable}\n",
    "\n",
    "Observe the sum of costs w.r.t. the number of change-points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6355000-788d-4254-a33c-67f836fff126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "\n",
    "# Choose detection method\n",
    "algo = rpt.KernelCPD(kernel=\"linear\").fit(tempogram)\n",
    "\n",
    "# Choose the number of changes (elbow heuristic)\n",
    "n_bkps_max = 20  # K_max\n",
    "# Start by computing the segmentation with most changes.\n",
    "# After start, all segmentations with 1, 2,..., K_max-1 changes are also available for free.\n",
    "_ = algo.predict(n_bkps_max)\n",
    "\n",
    "array_of_n_bkps = np.arange(1, n_bkps_max + 1)\n",
    "\n",
    "def get_bkps(signal: np.ndarray, n_bkps: int)->List[int]:\n",
    "    algo = rpt.KernelCPD(kernel=\"linear\").fit(signal)\n",
    "    bkps = algo.predict(n_bkps=n_bkps)\n",
    "    return bkps\n",
    "\n",
    "def get_sum_of_cost(algo, n_bkps) -> float:\n",
    "    \"\"\"Return the sum of costs for the change points `bkps`\"\"\"\n",
    "    bkps = algo.predict(n_bkps=n_bkps)\n",
    "    return algo.cost.sum_of_costs(bkps)\n",
    "\n",
    "\n",
    "fig, ax = fig_ax((7, 4))\n",
    "ax.plot(\n",
    "    array_of_n_bkps,\n",
    "    [get_sum_of_cost(algo=algo, n_bkps=n_bkps) for n_bkps in array_of_n_bkps],\n",
    "    \"-*\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.set_xticks(array_of_n_bkps)\n",
    "ax.set_xlabel(\"Number of change points\")\n",
    "ax.set_title(\"Sum of costs\")\n",
    "ax.grid(axis=\"x\")\n",
    "ax.set_xlim(0, n_bkps_max + 1)\n",
    "\n",
    "# Visually we choose n_bkps=5 (highlighted in red on the elbow plot)\n",
    "n_bkps = 5\n",
    "_ = ax.scatter([5], [get_sum_of_cost(algo=algo, n_bkps=5)], color=\"r\", s=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4268a304-ddbd-41a7-8fc0-cab55b0ba619",
   "metadata": {},
   "source": [
    "**Visually, we choose 5 change points** (highlighted in red on the elbow plot)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4157f11f-6413-49b8-9edf-9e4f493899cf",
   "metadata": {},
   "source": [
    "## Combining everything together {.smaller}\n",
    "\n",
    "Our pipeline has two blocks:\n",
    "\n",
    "- signal transformation,\n",
    "- change-point detection.\n",
    "\n",
    "We use the scikit-learn `Pipeline` pattern. We can use the rich ecosystem to calibrate our algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ec63d9-4520-44b1-a78d-b2653da62a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "\n",
    "class TempogramTransformer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, hop_length_tempo: int=HOP_LENGTH_TEMPO):\n",
    "        self.hop_length_tempo = hop_length_tempo\n",
    "\n",
    "    def fit(self, X=None, y=None, **kwargs):\n",
    "        \"\"\"Nothing happens in the .fit()\"\"\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: List[npt.NDArray]) -> List[npt.NDArray]:\n",
    "        out = list()\n",
    "        for signal in X:\n",
    "            tempogram = get_tempogram(\n",
    "                signal=signal,\n",
    "                hop_length_tempo=self.hop_length_tempo)\n",
    "            out.append(tempogram)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ChangePointDetector(BaseEstimator):\n",
    "    def __init__(self, n_bkps: int = 2):\n",
    "        self.n_bkps = n_bkps\n",
    "\n",
    "    def fit(self, X=None, y=None, **kwargs):\n",
    "        \"\"\"Nothing happens in the .fit()\"\"\"\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: List[npt.NDArray], **kwargs) -> List[List[int]]:\n",
    "        \"\"\"Return a list of segmentations.\n",
    "\n",
    "        A segmentation itself is a list of breakpoint indexes.\n",
    "        \"\"\"\n",
    "        out = list()\n",
    "        for signal in X:\n",
    "            bkps = get_bkps(signal=signal, n_bkps=self.n_bkps)\n",
    "            out.append(bkps)\n",
    "        return out\n",
    "    \n",
    "steps = [(\"tempogram_transformer\", TempogramTransformer()),\n",
    "         (\"change_detector\", ChangePointDetector(n_bkps=5))]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c2657c-a6e4-479e-aeb0-6cadd15b2b08",
   "metadata": {},
   "source": [
    "## Detecting change-points\n",
    "\n",
    "- We estimate changes with the defined pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3b5b8f-abbb-48c1-8dec-d562ed1e3af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "\n",
    "# Segmentation\n",
    "bkps, = pipeline.predict([signal])\n",
    "# Convert the estimated change points (frame counts) to actual timestamps\n",
    "bkps_times = librosa.frames_to_time(\n",
    "    bkps, sr=SAMPLING_RATE, hop_length=pipeline[\"tempogram_transformer\"].hop_length_tempo)\n",
    "\n",
    "# Displaying results\n",
    "fig, ax = fig_ax()\n",
    "_ = librosa.display.specshow(\n",
    "    tempogram.T,\n",
    "    ax=ax,\n",
    "    x_axis=\"s\",\n",
    "    y_axis=\"tempo\",\n",
    "    hop_length=pipeline[\"tempogram_transformer\"].hop_length_tempo,\n",
    "    sr=SAMPLING_RATE,\n",
    ")\n",
    "\n",
    "for b in bkps_times[:-1]:\n",
    "    ax.axvline(b, ls=\"--\", color=\"white\", lw=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f7def3-b1d6-4c47-bb91-891b7e69d626",
   "metadata": {},
   "source": [
    "Visually, the estimated change points indeed separate portions of signal with a relatively constant tempo profile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7b147f-8e70-408e-b185-5e676bb4e7f1",
   "metadata": {},
   "source": [
    "## Listening to the change-points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f1ade5-bd42-40de-96ed-76639f1c0a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute change points corresponding indexes in original signal\n",
    "bkps_time_indexes = (SAMPLING_RATE * bkps_times).astype(int).tolist()\n",
    "\n",
    "for (segment_number, (start, end)) in enumerate(\n",
    "    rpt.utils.pairwise([0] + bkps_time_indexes), start=1\n",
    "):\n",
    "    segment = signal[start:end]\n",
    "    print(f\"Segment n°{segment_number} (duration: {segment.size/SAMPLING_RATE:.2f} s)\")\n",
    "    display(Audio(data=segment, rate=SAMPLING_RATE))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849d06b0-8cc2-40c7-932c-d3cc95de82cf",
   "metadata": {},
   "source": [
    "## Some remarks on how to create and maintain Python librairies {.smaller}\n",
    "\n",
    ":::: {.columns}\n",
    "\n",
    "::: {.column width=\"50%\"}\n",
    "\n",
    "- Having a [documentation](https://centre-borelli.github.io/ruptures-docs/).\n",
    "    - generated from the code comments,\n",
    "    - add examples\n",
    "- Clean code:\n",
    "    - use code formatter ([black](https://black.readthedocs.io/en/stable/)),\n",
    "    - testing ([pytest](https://docs.pytest.org/en/7.2.x/)) and code coverage ([Codecov](https://about.codecov.io/)),\n",
    "    - lots of comments\n",
    "\n",
    ":::\n",
    "\n",
    "::: {.column width=\"50%\"}\n",
    "\n",
    "- Automatize everything with GitHub Actions.\n",
    "    - packaging and release,\n",
    "    - issue/PR management and changelog.\n",
    "\n",
    "More info [scikit-hep](https://scikit-hep.org/).\n",
    "\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
